

1.importing all tables from RDBMS to hadoop:
=========================================

sqoop import-all-table \
--connect jhdbc:mysql://localhost/retail_db \
--username root \
--password root \
--warhouse-dir 'user/data/sq_tables/' \
--autoreset-to-one-mapper ;


2.Exclude tables from RDBMS to sqoop:
=====================================
sqoop import-all-table \
--connect jhdbc:mysql://localhost/retail_db \
--username root \
--password root \
--exclude-table 'orders,customers' \
--warhouse-dir 'user/data/sq_tables/' \
--autoreset-to-one-mapper ;

Note:
-----
autoreset-to-one-mapper : it set to one mapper when any table had no primary key
u can't use split by

3.import data from rdbms table to hive table:
===========================================

sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password root \
--table orders \
--hive-import \
--hive-database hive_sq \
--hive-table hive_sq_orders \
-- m 1 ;

3.sqoop incremental/delta loads (lastmodified,append):
================================================

load historical data:(only once)
---------------------
sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password root \
--table order_delta \
--target-dir 'user/data/order_delta' \
--as-textfile \
--delete-target-dir \
-m 1;

to get updated records:(every day)
----------------------------
sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password root \
--table order_delta \
--target-dir 'user/data/order_delta' \
--check-column order_date \
--incremental append \
--last-value "2022-05-19" \
-m 1;