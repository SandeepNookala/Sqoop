
sqoop
--options-file D:/Big_Data/Sqoop/code/sqoop-connect 


1.importing all tables from RDBMS to hadoop:
=========================================

sqoop import-all-table \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password root \
--warhouse-dir 'user/data/sq_tables/' \
--autoreset-to-one-mapper ;


2.Exclude tables from RDBMS to sqoop:
=====================================
sqoop import-all-table \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password root \
--exclude-table 'orders,customers' \
--warhouse-dir 'user/data/sq_tables/' \
--autoreset-to-one-mapper ;

Note:
-----
autoreset-to-one-mapper : it set to one mapper when any table had no primary key
u can't use split by

3.import data from rdbms table to hive table:
===========================================

sqoop 
--options-file D:/Big_Data/Sqoop/code/sqoop-connect 
--table orders \
--hive-import \
--hive-database hive_sq \
--hive-table hive_sq_orders \
-- m 1 ;

3.sqoop incremental/delta loads (lastmodified,append):
================================================

load historical data:(only once)
---------------------

sqoop import \
--option-file D:/Big_Data/Sqoop/code/sqoop-connect \
--table order \
--target-dir /user/coludera/retail/ \
--delete-target-dir \
--fields-terminated-by ',' \
--lines-terminated-by ',' \
-m 3 ;

to get updated records:(every day)
----------------------------

sqoop import \
--option-file D:/Big_Data/Sqoop/code/sqoop-connect \
--table order \
--target-dir /user/coludera/retail/ \
--incremental append \
--check-column order_id \
--last-value '2023-05-01' \
--fields-terminated-by ',' \
--lines-terminated-by ',' \
-m 3 ;